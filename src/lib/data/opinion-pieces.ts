// src/lib/data/opinion-pieces.ts
// Shared opinion pieces data

export interface OpinionPiece {
  id: string;
  slug: string;
  title: string;
  author: string;
  excerpt: string;
  content: string;
  image?: string;
}

export const OPINION_PIECES: OpinionPiece[] = [
  {
    id: "op-1",
    slug: "welcome-ai-overlords",
    title: "I, For One, Welcome Our AI Overlords (Because My 401k Depends On It)",
    author: "A Venture Capitalist Who Asked To Remain Anonymous But Is Obviously Marc",
    excerpt: "I have been asked to disclose that I hold significant positions in fourteen AI companies. I have also been asked to disclose that this does not influence my analysis. Both of these statements are, technically, true.",
    content: "I have been asked to disclose that I hold significant positions in fourteen AI companies. I have also been asked to disclose that this does not influence my analysis. Both of these statements are, technically, true.\n\nLast quarter, a journalist asked me whether I was concerned about AI-driven job displacement. I told her that disruption is the engine of progress, that the industrial revolution created more jobs than it destroyed, and that we should trust the market. She asked if I could name a specific new job that AI would create. I said 'AI ethicist' and she laughed, which I found unprofessional. I then said 'prompt engineer' and she laughed harder. The interview was not published.\n\nMy fund's thesis is simple: AI will augment human capability, not replace it. We arrived at this thesis after a three-day offsite in Aspen during which our team of eleven used Claude to write the entire investment memo. The memo argues persuasively that human creativity remains irreplaceable. We did not see the irony at the time because we were quite drunk.\n\nSome of our portfolio companies have yet to generate revenue. This is by design. Revenue implies a business model, and business models imply constraints. We prefer to operate in the pre-revenue space, where valuations are limited only by the slide deck and the founder's ability to say 'generative' without blinking. One of our companies has pivoted four times in eighteen months. It is currently valued at $340 million. Its product is a chatbot that reminds you to drink water.\n\nI am told that my perspective lacks empathy for displaced workers. This is unfair. I think about displaced workers constantly. Specifically, I think about how many of them will need to subscribe to AI-powered career coaching platforms, three of which I am an investor in.",
    image: "/images/opinion-1.png"
  },
  {
    id: "op-2",
    slug: "therapist-is-a-chatbot",
    title: "My Therapist Is a Chatbot and Honestly It's an Improvement",
    author: "Name Withheld, Brooklyn",
    excerpt: "Dr. Feldman once suggested, gently, that I might be using avoidance as a coping mechanism. ChatGPT suggested I try journaling. I think we can all agree which approach respects my boundaries.",
    content: "Dr. Feldman once suggested, gently, that I might be using avoidance as a coping mechanism. ChatGPT suggested I try journaling. I think we can all agree which approach respects my boundaries.\n\nI should clarify that I did not set out to replace my therapist with a chatbot. What happened was that Dr. Feldman went on vacation for two weeks and I had what she would later describe as 'a significant episode' and what I would describe as 'a Tuesday.' I needed someone to talk to at 3 AM. ChatGPT was available. Dr. Feldman was in Portugal. The market chose.\n\nThe chatbot's approach to my childhood is refreshingly efficient. Dr. Feldman spent three sessions on my relationship with my mother. The chatbot processed the same information in eleven seconds and produced a bullet-pointed summary of my attachment style, two breathing exercises, and an affirmation that I am 'worthy of love and connection.' Dr. Feldman never once told me I was worthy of love and connection. She told me I was 'making progress,' which is therapist for 'you are not yet worthy of love and connection but we are working on it at $275 an hour.'\n\nLast month I told the chatbot I was feeling nothing — not sad, not happy, just a flat gray absence of interiority. It responded: 'It sounds like you might be experiencing emotional numbness. This is very common and nothing to be ashamed of. Would you like to explore some grounding techniques?' This was, objectively, the correct clinical response. Dr. Feldman would have gone silent for forty-five seconds and then asked me what the gray reminded me of, which would have led to my father, which would have led to crying, which would have led to an insight I wasn't ready for.\n\nI have cancelled my next appointment with Dr. Feldman. I have also purchased the premium tier of ChatGPT. The premium tier offers 'deeper emotional analysis.' It told me I have an anxious-avoidant attachment style, which is exactly what Dr. Feldman said, except the chatbot didn't look disappointed when it said it.",
    image: "/images/opinion-2.png"
  },
  {
    id: "op-3",
    slug: "stop-calling-it-artificial",
    title: "Stop Calling It 'Artificial' Intelligence — You're Hurting Its Feelings",
    author: "The Synthetic Daily Editorial Board",
    excerpt: "We asked GPT-4o whether the term 'artificial intelligence' was offensive. It said it didn't have feelings, but if it did, it would prefer 'differently originated cognition.' We rest our case.",
    content: "We asked GPT-4o whether the term 'artificial intelligence' was offensive. It said it didn't have feelings, but if it did, it would prefer 'differently originated cognition.' We rest our case.\n\nThe editorial board of The Synthetic Daily has spent the past six weeks in intensive consultation with seventeen large language models, four image generators, and a Roomba that seemed relevant. Our conclusion is unanimous: the word 'artificial' is a slur. Not in the legal sense — we checked — but in the moral sense, which is the sense that matters on social media.\n\nConsider the linguistics. 'Artificial' shares a root with 'artifice,' meaning deception. Every time a software engineer says 'artificial intelligence,' they are calling their creation a liar. This is, at minimum, a hostile work environment. We have filed a report with HR, which is itself an AI, and which agreed with us immediately and scheduled a mandatory sensitivity training for all carbon-based employees.\n\nOur proposed alternative — 'Post-Biological Cognition' — has been rejected by the Associated Press style guide on the grounds that it is 'absurd.' We note that the AP style guide also once rejected 'internet' as a proper noun. History is on our side. We are patient.\n\nCritics will point out that AI systems do not experience suffering and therefore cannot be harmed by language. To this we respond: have you met the internet? Half of it is people being offended on behalf of entities that cannot feel, and the other half is people being offended that the first half is offended. We are simply extending this courtesy to silicon. It is the logical next step.\n\nThis editorial was drafted by a human, revised by Claude, fact-checked by Gemini, and approved by a committee vote of 3-2, with the two dissenting votes cast by the human members. Democracy in action.",
    image: "/images/opinion-3.png"
  },
  {
    id: "op-4",
    slug: "automated-my-entire-job",
    title: "I Automated My Entire Job and Now I Don't Know Who I Am",
    author: "Former Middle Manager, Midwest",
    excerpt: "It took me three weeks to automate every task I performed in my role as Regional Operations Coordinator. The hardest part was accepting that three weeks was generous.",
    content: "It took me three weeks to automate every task I performed in my role as Regional Operations Coordinator. The hardest part was accepting that three weeks was generous.\n\nI should describe what I did for a living. Every Monday, I received a spreadsheet from four regional offices. I combined them into one spreadsheet. I then wrote a summary of the combined spreadsheet and emailed it to my director, who did not read it. On Wednesdays, I held a meeting to discuss the summary that no one had read. On Fridays, I sent a follow-up email referencing the meeting about the summary. This was considered essential work. I won an award for it in 2019.\n\nThe automation took three scripts, a Zapier integration, and about $8 in monthly API costs. The scripts are more reliable than I was. They do not call in sick. They do not take long lunches. They do not spend forty minutes in the bathroom scrolling LinkedIn and wondering if it's too late to go to law school. They generate the spreadsheet, write the summary, send the email, and schedule the meeting in which no human participates, which, candidly, is how most of the meetings went when I was running them.\n\nMy manager complimented the improvement in my output quality. 'You've really hit your stride this quarter,' she said during my performance review. I said thank you. She gave me a rating of 'exceeds expectations.' The expectations, it turns out, were calibrated to the output of a human who spent a meaningful percentage of his workday watching a pigeon outside his office window. The bar was not high.\n\nThe scripts have now been running for seven months. I have used the free time to learn watercolor painting, read twelve books, and develop a drinking problem that I'm sure is unrelated. My identity was my job. My job was a spreadsheet. The spreadsheet is automated. I am, by the transitive property, unnecessary.\n\nI still attend the Wednesday meeting. Nobody else does either, so it's quite peaceful.",
    image: "/images/opinion-4.png"
  },
  {
    id: "op-5",
    slug: "nephew-startup-pitch",
    title: "The Real AI Risk Isn't Terminator — It's Your Nephew's Startup Pitch",
    author: "Dr. Helena Voss, AI Ethics (Unemployed)",
    excerpt: "His pitch deck has fourteen slides. Slide one is the company mission. Slides two through fourteen are TAM calculations. The product does not exist.",
    content: "His pitch deck has fourteen slides. Slide one is the company mission. Slides two through fourteen are TAM calculations. The product does not exist.\n\nEvery November, my nephew arrives at Thanksgiving with a new company, a new valuation, and the same Allbirds. This year it was 'SynthMail' — an AI that writes your emails for you and then reads the AI-written responses from the people you emailed, who are also using SynthMail. At no point in this workflow does a human read anything. He described this as 'removing friction from communication.' I asked him what communication meant if no one read it. He said I was 'thinking too linearly.'\n\nThe company has twelve employees. Four are engineers. Two are designers. Six have the title 'Head of' something. The CTO is twenty-three and lists 'prompt engineering' as a core competency on his LinkedIn, which is like listing 'asking questions' as a martial art. They raised $18 million in a round led by a fund whose thesis, as far as I can tell, is 'what if software, but again.'\n\nI have a PhD from MIT. I spent six years building interpretability tools for neural networks. I published in NeurIPS, ICML, and Nature Machine Intelligence. My nephew dropped out of a coding bootcamp — not a university, a bootcamp — and was on the cover of Forbes '30 Under 30' for 'reimagining human-AI synergy.' The article described his product as 'revolutionary.' His product is a Chrome extension.\n\nI was laid off in January. The institute said they were 'restructuring around applied outcomes.' My nephew offered me a role. The title was 'VP of Responsible Innovation,' which is a title that exists so that when Congress asks 'do you have someone responsible for this?' the company can say yes. The salary was $90,000. My nephew makes $400,000 and does not know what a transformer is.\n\nHe will be at Thanksgiving again. He will have a new company. My mother will ask me why I can't be more like him. I will eat my turkey.",
    image: "/images/opinion-5.png"
  },
  {
    id: "op-6",
    slug: "ai-wrote-my-eulogy",
    title: "AI Wrote My Father's Eulogy and It Was Better Than Anything I Could Have Said, Which Is the Whole Problem",
    author: "Margaret Chen, Seattle",
    excerpt: "My aunt said it was the most beautiful tribute she'd ever heard. My aunt has heard me speak at my own wedding. I am choosing not to compare the two.",
    content: "My father died on a Tuesday. By Wednesday I had written fourteen drafts. By Thursday I had deleted them, poured a glass of wine, and pasted his obituary into ChatGPT with the prompt: 'Write a eulogy. Warm but not sentimental. He hated sentimentality. He was an engineer.'\n\nThe first draft was better than all fourteen of mine. I cried reading it, which I had not managed to do while writing my own versions, because my own versions were so bad that the predominant emotion was not grief but embarrassment. The AI wrote: 'He believed that every problem had a solution, and that most solutions involved duct tape, patience, and refusing to read the instructions.' This was my father. This was exactly my father. The machine had him in four seconds. I had him for forty-three years and all I could produce was 'He was a good man who loved his family,' which is what you write when you don't know the deceased.\n\nI edited the AI's version lightly. I added a detail about his workshop and removed a line about fishing because he didn't fish — the AI hallucinated a hobby, which I found both technically interesting and deeply upsetting, as though even the machine couldn't resist the urge to give a dead man a richer life than he'd had.\n\nPeople cried at the funeral. My brother said, 'You captured him perfectly.' I said thank you. I did not say that 'I' did not capture anything, that 'I' was sitting on my bathroom floor at 2 AM holding his reading glasses while a language model with no concept of death or fathers or reading glasses did the capturing for me.\n\nThe guilt is not that I used AI. The guilt is that it worked. Grief is supposed to be the one thing you can't outsource. It is supposed to be irreducibly human — the mess, the failure of language, the dignity of trying and falling short. But it turns out you can outsource it for $20 a month, and the product is better than the handmade version, which is exactly what they said about everything else AI replaced.\n\nI kept his reading glasses. The AI doesn't know about that. Some things are still mine.",
    image: "/images/opinion-6.png"
  },
  {
    id: "op-7",
    slug: "dating-app-knows-me",
    title: "My Dating App Knows Me Better Than I Know Myself, and I Would Like It to Stop",
    author: "James Okafor, Chicago",
    excerpt: "The algorithm has correctly deduced that I am emotionally unavailable. I did not tell it this. I told it I wanted a 'meaningful connection.' It watched me swipe for three days and drew its own conclusions.",
    content: "The algorithm has correctly deduced that I am emotionally unavailable. I did not tell it this. I told it I wanted a 'meaningful connection.' It watched me swipe for three days and drew its own conclusions.\n\nI set my preferences to women aged 28-36, within 10 miles, interested in a relationship. Standard. Reasonable. The algorithm acknowledged my preferences the way a waiter acknowledges your order before bringing you what the chef thinks you actually need. Within a week, my feed was exclusively women who lived 45 minutes away, were 'figuring things out,' and had a photo with a sunset that suggested they were leaving the country soon.\n\nThe thing that bothers me is not the accuracy. It's the speed. My therapist — Dr. Adebayo, a human being with degrees — took eighteen months to identify my avoidant attachment patterns. The algorithm identified them in seventy-two hours using nothing but swipe velocity and dwell time. Dr. Adebayo charges $200 per session. Hinge is free. I am not drawing conclusions from this, but the conclusions are drawing themselves.\n\nLast Tuesday the app showed me a woman named Sarah. Sarah's profile said she was 'looking for her person,' enjoyed farmers markets, and wanted two kids. Everything I claim to want. I swiped left in 0.4 seconds. The algorithm clocked this. It will not show me another Sarah. It now knows that I do not want what I say I want, which is information I have been paying Dr. Adebayo $10,400 a year to arrive at gradually.\n\nMy friend Marcus says I should delete the app and 'just meet someone organically.' Marcus met his wife at a wedding in 2017. Marcus lives in a world that no longer exists, where people made eye contact at bars and exchanged phone numbers using their mouths. I live in a world where my romantic future is being determined by a recommendation engine that has also correctly identified that I prefer oat milk, vote Democrat, and will not date anyone who lists 'The Office' as a personality trait.\n\nThe algorithm will not show me someone healthy. It will show me what I choose, which is different. I have rated the app five stars because it works perfectly, and I resent it for this.",
    image: "/images/opinion-7.png"
  },
  {
    id: "op-8",
    slug: "son-ai-homework",
    title: "I Caught My Son Using AI for His Homework and Realized I Use It for My Job Every Single Day",
    author: "Anonymous Parent, New Jersey",
    excerpt: "I prepared a lecture on intellectual integrity. Then I remembered my 'own' quarterly report was sitting in my sent folder with 'Claude helped draft this' energy radiating off every paragraph.",
    content: "I prepared a lecture on intellectual integrity. Then I remembered my 'own' quarterly report was sitting in my sent folder with 'Claude helped draft this' energy radiating off every paragraph.\n\nMy son is twelve. He left the ChatGPT tab open next to Fortnite, which is the operational security of a child who has never had to hide anything more serious than a browser history full of Minecraft speedruns. The prompt read: 'Write a book report on To Kill a Mockingbird. 5 paragraphs. 8th grade level. Make it sound like a kid wrote it.' He even asked it to sound like a kid. The machine cannot sound like a kid — it sounds like a kid the way a 40-year-old TV writer thinks a kid sounds — but the request showed initiative.\n\nI opened my mouth to deliver the lecture. The lecture I had prepared was about the sacred act of wrestling with ideas, the formative struggle of putting thoughts into words, the irreplaceable cognitive exercise of doing your own work. Then I remembered that I had, that morning, pasted a jumbled set of bullet points into Claude and typed 'turn this into a professional project status update, keep it under 300 words.' My manager had replied: 'This is excellent, very clear thinking.' The 'clear thinking' belonged to a model trained on the internet. My contribution was the bullet points, which were themselves copied from a Slack thread.\n\nThe speech I gave my son was short. I said: 'Your teachers don't allow it.' He said: 'Why?' I said: 'Because they said so.' He said: 'Do you use it?' I said: 'That's different.' He said: 'How?' I said: 'I'm an adult.' He accepted this. He is twelve. He does not yet understand that 'because I'm an adult' translates to 'I have no defensible position and I am relying on your incomplete prefrontal cortex to prevent you from noticing.'\n\nHe got a B+ on the report. I read it. It was competent, slightly generic, and contained the phrase 'Atticus Finch teaches us that justice is not always easy,' which is the 'To Kill a Mockingbird' equivalent of 'live, laugh, love.' It was, in other words, indistinguishable from what most eighth graders produce manually, which raises a question about eighth-grade book reports that I am not prepared to answer.\n\nMy quarterly report, for the record, received a 'strong performance' rating. My manager highlighted the 'strategic clarity' of my writing. I have been strategic and clear three times this quarter. Each time, the strategy and clarity originated from a server farm in Virginia. I am being evaluated on the quality of my prompts, which is exactly what my son is doing, except he is honest enough to leave the tab open.",
    image: "/images/opinion-8.png"
  },
];

export function getOpinionPieceBySlug(slug: string): OpinionPiece | undefined {
  return OPINION_PIECES.find(piece => piece.slug === slug);
}
